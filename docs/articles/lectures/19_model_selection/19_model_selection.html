<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>LECTURE 19: model selection</title>
    <meta charset="utf-8" />
    <meta name="author" content="   Fall 2021" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="FANR6750.css" type="text/css" />
    <link rel="stylesheet" href="FANR6750-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# LECTURE 19: model selection
## FANR 6750 (Experimental design)
### <br/><br/><br/>Fall 2021

---




# outline 

&lt;br/&gt;

1) Motivation

&lt;br/&gt;

--

2) AIC

&lt;br/&gt;

--

3) Multi-model inference



---
# motivation

#### As scientists, we usually have more than one hypothesis  

&lt;br/&gt;

--

#### Consequently, we usually want to evaluate more than one model  

&lt;br/&gt;

--

#### **Model selection** is the process of choosing which model is most supported by our data

&lt;br/&gt;

--

#### In cases where more than one model is highly supported, we can make inferences from multiple models using model averaging

---
# questions

&lt;br/&gt;

#### How do we know which model is best?  

&lt;br/&gt;

--

#### Are any of them any good?  

&lt;br/&gt;

--

#### What is a good model?

---
# what is a good model?

### Explanation

&gt; A good model should be a good approximation of reality. It should describe how things actually work  


In other words, a good model should describe the processes that give rise to the patterns we observe  

&lt;br/&gt;

--

### Prediction

&gt; A good model should have good predictive abilities  

---
# explanation

#### As scientists, we want:

&gt; “an explanation that is as simple as possible, but no simpler” - Einstein (paraphrased by Reader’s Digest!)  

&lt;br/&gt;
&lt;br/&gt;

--

#### Why do we want simplicity?

---
# fit and over-fit

#### `\(\large R^2\)` is a measure of model fit  

--

#### Questions

- Does the addition of a new predictor variable always increase `\(R^2\)`?  

--

- Do we want the model with the highest `\(R^2\)`?  

--

- What is the harm in adding “extra” predictor variables?

&lt;br/&gt;

--

#### Overly-complicated models don’t predict well. They are too specific to a particular dataset.

---
# fit and over-fit

&lt;br/&gt;

&lt;img src="19_model_selection_files/figure-html/unnamed-chunk-1-1.png" width="648" style="display: block; margin: auto;" /&gt;

---
# prediction


#### Predictive ability is assessed by comparing observed and expected values 

--

#### In non-scientific fields, we might not care about describing how things actually work. We might only care about prediction  

--

#### However, in scientific contexts we want models that are good at description and prediction  

--

#### Excellent paper:

&gt; Tredennick, A. T., Hooker, G., Ellner, S. P., &amp; Adler, P. B. (2021). A practical guide to selecting models for exploration, inference, and prediction in ecology. [Ecology, 102(6), e03336.](https://esajournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ecy.3336?casa_token=lJ3FPGPERrEAAAAA:0iXyzHKOWSJCr7lnwryWsJuXNTCITGhZa6bsRL5rSR8deXYWDmw99yhUPHomkVmf3iso_lZsahbXYEc)

---
# model selection approaches

**Comparison of 2 models**  
- Likelihood-ratio test  

--

**Stepwise procedures**  
- Forward/backward/stepwise selection  

--

**Information-theortic approaches**  
- Akaike’s Information Criterion (AIC)  

--

**Cross-validation**  
- Leave-one-out  
- K-fold  

--

**Out-of-sample validation**  
- Compare predictions to new data

---
class: middle, inverse, center

# aic

---
# aic

#### Minus twice the (maximized) log-likelihood plus two times the number of parameters

`$$\Large AIC = -2L(\hat{\theta}, y) + 2K$$`

--

#### Or, when ordinary least squares (OLS) is used for estimation, AIC is based on the residual sums-of-squares (RSS):

`$$\Large AIC = n \log(RSS/n) + 2K$$`
--

#### The key is to recognize that

&gt; AIC = measure of fit + complexity penalty

&lt;br/&gt;

--

AIC is asymtotically equivalent to leave-one-out cross-validation

---
# aic in practice

1) Select a set of candidate models

--

2) Fit the models to the data (maximize the likelihood or minimize the RSS)  

--

3) Compute the AIC of each model  

--

4) Rank the models by AIC (lower AIC is better)  

--

5) Compute the difference in AIC scores between the best model, and every other model  

`$$\large \Delta_i = AIC_i - AIC_{min}$$`
--

6) Compute the so-called Akaike weight of each model:

`$$\large w_i = \frac{exp(-1/2\Delta_i)}{\sum_i exp(-1/2 \Delta_i)}$$`

--

7) A model with `\(w = 0.6\)` is twice as likely to be the best model in the set as a model with `\(w = 0.3\)`

---
# presentation of results

&lt;br/&gt;

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; RSS &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; K &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(\Delta_{AIC}\) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; w &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 300 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 113.8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.98 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 320 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 122.3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8.4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.02 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 330 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 125.4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 11.5 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 330 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 129.4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 15.5 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

???

Residual sum of squares (RSS) replaced by log likelihood if using maximum likelihood estimation

---
# small sample size adjustment

&lt;br/&gt;
&lt;br/&gt;

#### The last term is the “bias adjustment term”

`$$\Large AIC_c = n \log(RSS/n) + 2K + \frac{2K(K + 1)}{n - K - 1}$$`

---
# notes about aic


#### AIC is not a test  

--

#### AIC is a relative measure. You can’t compare the AICs of models fit to different datasets  

--

#### In other words, all models must be fit to the exact same data  

--

#### There will always be a model with the lowest AIC. But all of the models in the set could be terrible  

--

#### Always assess the fit of your best model!

---
# aic as an alternative to null hypothesis testing

#### The use of AIC avoids some of the limitations of null hypothesis testing, such as:  

--

- Null hypotheses are rarely true  

--

- A *p*-value tells us nothing about the alternative hypothesis  

--

- Specification of `\(\alpha\)` is arbitrary  

--

- Statistical significance is a function of sample size  

--

- Statistical significance does not equal biological significance  

---
class: inverse, center, middle

# multi-model inference

---
# multi-model inference

&lt;br/&gt;

#### What if several models have similar weights?  

&lt;br/&gt;

--

#### Multi-model inference involves using all of the models in the set of models  

---
# multi-model inference

&lt;br/&gt;

#### The key is to do a weighted average of parameters or predictions  

`$$\Large\bar{\hat{\theta}} = \sum_{i=1}^{R} \hat{\theta}_i w_i$$`

&lt;br/&gt;

where `\(\hat{\theta}_i\)` is a parameter or a predicted value from model `\(i\)` in the set of `\(R\)` models

---
# averaging parameters

&lt;br/&gt;

#### In the case of linear models, we might want to average the `\(\large \beta\)` parameters  

--

#### But not all parameters are in every model. What do we do?

--

#### Two options:

1) Average estimates over models in which the parameter occurs (*bad idea*)  

--

2) Average estimates over all models, and set the estimate to 0 when the parameter is not in the model

---
# example

&lt;br/&gt;


&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Intercept &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Elevation &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Elevation squared &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Chaparral &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; weight &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm7 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 30.7 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0083 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.80 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 28.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0120 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -0.026 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.093 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.19 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Average &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 29.9 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0089 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ??? &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; ??? &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


---
# example

&lt;br/&gt;


&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Intercept &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Elevation &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Elevation squared &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Chaparral &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; weight &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm7 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 30.7 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0083 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.000 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.80 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 28.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0120 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -0.026 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.093 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.19 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Average &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 29.9 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.0089 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; -0.005 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.018 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;br/&gt;

--

Be aware that some people recommend that you never model average regression coefficients. However, it’s always fine to model average predictions  


---
# model-averaged predictions

#### Same concept, applied to predicted values instead of parameter estimates  

--

#### Example: predict jay abundance when in Oak habitat at 1000 m elevation, and 10% chaparral

&lt;br/&gt;

--

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Predicted abundance &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; weight &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm7 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 42.17 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.80 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; fm8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 45.95 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.19 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Average &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 42.47 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# model-averaged se and ci

&lt;br/&gt;

#### We now know how to use model averaging to compute `\(\large \hat{\theta}\)`

&lt;br/&gt;

--

#### But, how do we calculate the SE or CI?

---
# unconditional se


&lt;br/&gt;
&lt;br/&gt;

`$$\Large SE(\bar{\hat{\theta}}) = \sum_{i=1}^{R} w_i \sqrt{var(\hat{\theta}_i + (\hat{\theta}_i - \bar{\hat{\theta}})^2}$$`

---
# example

&lt;br/&gt;

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(\hat{\beta}\) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SE &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; weight &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.30 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.5 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.25 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.26 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.2 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

`$$\large \bar{\hat{\beta}} = 1.2 \times 0.5 + 1.1 \times 0.3 + 1.4 \times 0.2 = 1.21$$`

--

`$$\begin{aligned}
  SE = &amp;0.5 \sqrt{0.3^2 + (1.2-1.21)^2} + \\
  &amp;0.3 \sqrt{0.25^2 + (1.1-1.21)^2} + \\
  &amp;0.2 \sqrt{0.26^2 + (1.4-1.21)^2} \\
  &amp;= 0.29
\end{aligned}$$`

---
# relative variable importance

&lt;br/&gt;

#### Which of the predictor variables is most important?  

&lt;br/&gt;

--

#### Burnham and Anderson recommend using `\(\large w_+(\beta_j)\)`, the sum of the AIC weights over all models that include `\(\large \beta_j\)`

---
# example

&lt;br/&gt;

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Model &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(\hat{\beta}_1\) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(\hat{\beta}_2\) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(\hat{\beta}_3\) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; \(w\) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.6 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; - &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

#### Variable importance

`$$\begin{aligned}
  w_+(\beta_1) = 0.4 + 0.3  + 0.3 &amp; = 1.0\\
  w_+(\beta_2) = 0.4 &amp; = 0.4\\
  w_+(\beta_3) = 0.3  + 0.3 &amp; = 0.6
\end{aligned}$$`

---
# summary

Information-theoretic approaches avoid many of the problems associated with null hypothesis testing

--

Focus is on:  

- Model comparision  

- Strength of evidence for each model  

- Estimates of effect sizes  

--

Requires much more thought than accept/reject approach, but just like any method, it is easy to abuse  

--

Additional references  

&gt; Burnham, K.P. and D.R. Anderson. 2002. Model Selection and Multimodel Inference. Springer (well known book)


&gt; [http://www.stats.ox.ac.uk/~ripley/ModelChoice.pdf](http://www.stats.ox.ac.uk/~ripley/ModelChoice.pdf) (good overview)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
