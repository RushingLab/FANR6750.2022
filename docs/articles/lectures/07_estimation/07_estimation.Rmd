---
title: "LECTURE 7: parameter estimation"
subtitle: "FANR 6750 (Experimental design)"
author: "<br/><br/><br/>Fall 2021"
output:
  xaringan::moon_reader:
    css: ["default", "FANR6750.css", "FANR6750-fonts.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, echo = FALSE, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center', warning=FALSE, message=FALSE, 
                      fig.retina = 2, fig.width = 9, fig.height = 7)
library(WILD3810)
library(emo)
library(kableExtra)
library(dplyr)
library(FANR6750)
# library(gganimate)
```

# outline 

<br/>

1) Motivation

<br/>

--

2) Example

<br/>

--

3) Graphical displays


---
class: inverse

# motivation

<br/>

Thus far, we have approached ANOVA from a statistical hypothesis testing standpoint only.  

<br/>

--
This approach and the use of statistical significance alone has been criticized because:  

--
- Null hypotheses are almost always known to be false *a priori*  

--
- $\alpha$ levels are arbitrary  

--
- Statistical significance is based on sample size  

--
- Statistical and biological significance are easily confused  

<br/>
--

Practitioners often are not interested in whether or not a null hypothesis can be rejected, but rather what the magnitude of the treatment effect is  

---
# parameter estimation

Often an investigator wants to obtain one or more estimates of parameters after (or as part of) an analysis of variance

```{r}
est_df <- data.frame(Parameter = c('\\(\\mu\\)',
                                   '\\(\\mu + \\alpha_i\\)',
                                   '\\(\\alpha_i\\)',
                                   '\\(\\mu_i - \\mu_{i^\\prime}\\)',
                                   '\\(\\sum_i a_i \\mu_i\\)'),
                     Description = c("Overall mean",
                                     "The \\(i\\)th treatment mean",
                                     "The \\(i\\)th treatment effect",
                                     "Difference between 2 means",
                                     "Some linear combination of parameters"))

est_df %>%
  kable(format = 'html', align = "c", escape = FALSE)
```


---
# confidence intervals

#### For each estimate, we often want a confidence interval to quantify uncertainty 

<br/>

--

#### What is a confidence interval? $^*$

> An interval [a,b] that is likely to include the true parameter of interest  

--

> If we calculated the x% confidence interval on an infinite number of samples from the population, x% of the intervals would contain the true parameter value

<br/>

--

#### In the context of ANOVA, the formula is:

$$\large CI_{1-\alpha} = point\; estimate \pm t_{\alpha/2,a(n-1)}\timesSE$$ 
???

$^*$Do you find confidence intervals confusing? If so, you are not alone. Here a few resources to help:

- A [nice webapp](https://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm) for simulating samples and confidence intervals  

- Tthis blog](https://econometricsense.blogspot.com/2018/12/thinking-about-confidence-intervals.html) does a nice job explaining that it's the interval, not the true value, that is the random variable. That is, the true parameter value is a fixed point. But every time we collect a sample, the bounds of the confidence interval we calculate will change 

- [Another metaphor](https://medium.com/@EpiEllie/having-confidence-in-confidence-intervals-8f881712d837) for thinking about what a confidence interval is

---
# standard errors

#### The standard error (SE) is the standard deviation of the sampling distribution of a statistic  
<br/>

--

#### We usually estimate the SE using a single sample of data  

<br/>

--

#### But the appropriate equation for the SE depends on the statistic of interest  

---
# standard errors

<br/>

```{r}
se_df <- data.frame(Parameter = c("Mean", "Treatment mean",
                                  "Difference in means", "Linear Combination"),
                    Symbol = c('\\(\\mu\\)',
                                   '\\(\\mu_i = \\mu + \\alpha_i\\)',
                                   '\\(\\mu_i - \\mu_{i^\\prime}\\)',
                                   '\\(\\sum_i a_i \\mu_i\\)'),
                    Point = c('\\(\\bar{y}.\\)',
                                   '\\(\\bar{y}_i\\)',
                                   '\\(\\bar{y}_i - \\bar{y}_{i^\\prime}\\)',
                                   '\\(\\sum_i a_i \\bar{y}_i\\)'),
                     SE = c('\\(\\sqrt{MSe/N}\\)',
                                   '\\(\\sqrt{MSe/n_i}\\)',
                                   '\\(\\sqrt{MSe(N-n_i)/n_i N}\\)',
                                   '\\(\\sqrt{MSe \\sum_i a_i^2/n_i}\\)'))

se_df %>%
  kable(format = 'html', align = "c", escape = FALSE)
```

--

#### Note: Confidence intervals based on these SEs are not adjusted for multiple comparisons  

---
# chain saw example

```{r echo = FALSE}
cs <- data.frame(gm = c(NA, NA, NA, NA, NA, "Group means"),
                 A = c(42,17,24,39,43, 33),
                 B = c(28,50,44,32,61, 43),
                 C = c(57,45,48,41,54, 49),
                 D = c(29,40,22,34,30, 31))
options(knitr.kable.NA = '')
cs %>%
  kable("html", align = 'c', col.names = c("", "A", "B", "C", "D"), booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = TRUE, font_size = 14) %>%
  add_header_above(c(" " = 1, "Brand" = 4)) %>%
  footnote(general = "MSe = 101.25")
```

--

#### What types of confidence intervals can we compute?

---
# displaying confidence intervals

```{r}
data("sawData")

cs <- sawData %>% 
  group_by(Brand) %>% 
  summarise(mu = mean(y)) %>%
  mutate(muLCI = mu - 2.12 * sqrt(101.25/5),
         muUCI = mu + 2.12 * sqrt(101.25/5),
         alpha = mu - mean(sawData$y),
         alphaLCI = alpha - 2.12 * sqrt((101.25 * 15)/100),
         alphaUCI = alpha + 2.12 * sqrt((101.25 * 15)/100))

ggplot(cs, aes(x = Brand, y = mu)) +
  geom_col() +
  geom_errorbar(aes(ymin = muLCI, ymax = muUCI), width = 0.1) +
  labs(title = "Group means") +
  scale_y_continuous("Kickback angle")
```

---
# displaying confidence intervals

```{r}
ggplot(cs, aes(x = Brand, y = mu)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = muLCI, ymax = muUCI), width = 0.1) +
  labs(title = "Group means") +
  scale_y_continuous("Kickback angle")
```

---
# displaying confidence intervals

```{r}
ggplot(cs, aes(x = Brand, y = alpha)) +
  geom_hline(yintercept = 0, linetype = "longdash", color = "grey50") +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = alphaLCI, ymax = alphaUCI), width = 0.1) +
  labs(title = "Effect sizes") +
  scale_y_continuous("Difference in kickback angle")
```

---
# displaying confidence intervals

```{r}
cs2 <- data.frame(Brand = c("A-B", "A-C", "A-D", "B-C", "B-D", "C-D"),
                  mu = c(cs$mu[1] - cs$mu[2], cs$mu[1] - cs$mu[3], cs$mu[1] - cs$mu[4],
                         cs$mu[2] - cs$mu[3], cs$mu[2] - cs$mu[4], cs$mu[3] - cs$mu[4]))

cs2 <- mutate(cs2, LCI = mu - 2.12 * sqrt((101.25 * 0.4)),
                   UCI = mu + 2.12 * sqrt((101.25 * 0.4)))

ggplot(cs2, aes(x = Brand, y = mu)) +
  geom_hline(yintercept = 0, linetype = "longdash", color = "grey50") +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = LCI, ymax = UCI), width = 0.1) +
  labs(title = "Effect sizes") +
  scale_y_continuous("Difference in kickback angle")
```

---
# summary

- Confidence intervals allow one to focus on effect sizes and statistical significance at the same time  

<br/>

--

- If $p < 0.05$, a 95% CI will not include 0 and vice versa  

<br/>

--

- If the CIs of two means do not overlap, the difference is statistically different. However, if the CIs of two means overlap, it does not necessarily indicate that there is no difference  

<br/>

--

- It is better to assess if the CI of the difference in means includes 0
